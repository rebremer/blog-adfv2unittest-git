variables:
  # Azure DevOps settings
  AzureServiceConnectionId: '<<your Azure DevOps SPN>>'
  # Change environment variables used in bash scripts with your own
  RG: '<<your resource group>>'
  # fixed Environment variables, no need for unique values
  LOC: '<<your Azure region>>'
  ADFV2NAME: '<<your Azure Data Factory name>>'
  SUBSCRIPTIONID: '<<your subscription id>>'
  BACPACFILE: 'WideWorldImporters-Standard.bacpac'
  SQLSERVER: '<<your sqlserver name, without .database.windows.net>>'
  SQLDATABASE: '<<your database name>>'
  SQLSERVICEOBJECTIVE: 'BC_Gen5_2'
  # In case AZURE_DEVOPS_SPN_DB_ADMIN = 0 (without _), then ADFv2 MI becomes SQLDB AAD admin 
  # Local SQL user will be used by pytest to query database state and thus is not necessary to have directory reader rights. 
  # Notice that in a production situation, ADFv2 MI should never be SQLDB Admin.
  # In case AZURE_DEVOPS_SPN_DB_ADMIN = 1 (without _), then Azure DevOps SPN is SQLDB AAD admin and ADFv2 MI is addes as external user
  # To do this, Azure DevOps SPN needs to have directory reader rights, see  https://docs.microsoft.com/en-us/azure/azure-sql/database/authentication-aad-service-principal
  AZUREDEVOPSSPNDBADMIN: 0
trigger:
- master

resources:
  repositories:
  - repository: blog-adfv2unittest-cicd # change with your own repo name when necessary
    type: git
    name: blog-adfv2unittest-devops
    ref: main
  - repository: blog-adfv2unittest-deployadfv2 # change with your own repo name when necessary
    type: git
    name: blog-adfv2unittest-devops
    ref: adf_publish

stages:
- stage: Build
  displayName: Build model and docker image
  jobs:
  - job: CreateBuildArtifactScriptsBacpac
    pool:
      vmImage: 'ubuntu-latest'
    steps:
    - checkout: blog-adfv2unittest-cicd
      path: blog-adfv2unittest-cicd
    - checkout: blog-adfv2unittest-deployadfv2
      path: blog-adfv2unittest-deployadfv2
    - task: CopyFiles@2
      displayName: 'Copy scripts to: $(Build.ArtifactStagingDirectory)'
      inputs:
        SourceFolder: '../blog-adfv2unittest-cicd'
        TargetFolder: '$(Build.ArtifactStagingDirectory)/blog-adfv2unittest-cicd'
    - task: CopyFiles@2
      displayName: 'Copy ADFv2 ARM to: $(Build.ArtifactStagingDirectory)'
      inputs:
        SourceFolder: '../blog-adfv2unittest-deployadfv2'
        TargetFolder: '$(Build.ArtifactStagingDirectory)/blog-adfv2unittest-deployadfv2'
    - publish: $(Build.ArtifactStagingDirectory)
      displayName: 'Upload package'
      artifact: drop
- stage: DeployTest
  displayName: 'Run unit tests ADFv2'
  dependsOn: Build
  condition: succeeded()
  jobs:
  - deployment: DeployTestADFv2
    pool:
      vmImage: 'ubuntu-latest'
    environment: DeployTestADFv2
    strategy:
      runOnce:
        deploy:
          steps:
          - task: AzurePowerShell@4
            displayName: 'Create ADFv2 instance with MI'
            inputs:
              azureSubscription: $(AzureServiceConnectionId)
              ScriptType: InlineScript
              Inline: "Set-AzDataFactoryV2 -ResourceGroupName $(RG) -Location $(LOC) -Name $(ADFV2NAME) -Force"
              azurePowerShellVersion: LatestVersion
          - task: AzureResourceManagerTemplateDeployment@3
            displayName: 'Deploy ARM template ADFv2'
            inputs:
              azureResourceManagerConnection: $(AzureServiceConnectionId)
              subscriptionId: $(SUBSCRIPTIONID)
              resourceGroupName: $(RG)
              location: $(LOC)
              csmFile: '$(Pipeline.Workspace)/drop/blog-adfv2unittest-deployadfv2/blog-adfv2unittest3-adfv2/ARMTemplateForFactory.json'
              csmParametersFile: '$(Pipeline.Workspace)/drop/blog-adfv2unittest-deployadfv2/blog-adfv2unittest3-adfv2/ARMTemplateParametersForFactory.json'
              overrideParameters: "-factoryName $(ADFV2NAME) -AzureSqlDatabase2_connectionString \"Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=@{linkedService().sqlserver};Initial Catalog=@{linkedService().database}\" -dataFactory_properties_globalParameters_sqlserver_value $(SQLSERVER).database.windows.net -dataFactory_properties_globalParameters_database_value $(SQLDATABASE)"
              #overrideParameters: "-factoryName $(ADFV2) -dataFactory_properties_globalParameters_akv_url_value $(akv_url) -dataFactory_properties_globalParameters_stor_url_value $(stor_url) -dataFactory_properties_globalParameters_stor_name_value $(STOR) -dataFactory_properties_globalParameters_cosmosdb_name_value $(COSMOSDBNAME) -dataFactory_properties_globalParameters_dbr_resource_id_value $(dbr_resource_id) -dataFactory_properties_globalParameters_workspace_id_url_value $(workspace_id_url) -dataFactory_properties_globalParameters_cluster_id_value $(cluster_id) -dataFactory_properties_globalParameters_vaultBaseUrl_value $(akv_url) -dataFactory_location $(LOC) -dataFactory_properties_globalParameters_notebook_name_value /insert_data_CosmosDB_Gremlin.py"
          - task: AzureCLI@2
            displayName: 'Create resources'
            inputs:
              azureSubscription: $(AzureServiceConnectionId)
              scriptType: bash
              scriptPath: '$(Pipeline.Workspace)/drop/blog-adfv2unittest-cicd/1_create_resources.sh'
          - task: AzureCLI@2
            displayName: 'Create bearer token'
            inputs:
              azureSubscription: $(AzureServiceConnectionId)
              scriptType: bash
              scriptPath: '$(Pipeline.Workspace)/drop/blog-adfv2unittest-cicd/2_create_tokens.sh'
          - script: |
              pip install pytest
              pip install pytest-cov
              pip install msrestazure
              pip install adal
              pip install pyodbc
              python -m pytest tests --rg $(RG) --subscriptionid $(SUBSCRIPTIONID) --tokenadf $(tokenadf) --tokendb $(tokendb) --adfv2id $(adfv2id) --adfv2name $(ADFV2NAME) --sqlserver $(SQLSERVER) --sqldatabase $(SQLDATABASE) --sqllogin '$(sqllogin)' --sqlpassword '$(sqlpassword)' --azuredevopsspndbadmin $(AZUREDEVOPSSPNDBADMIN) --doctest-modules --junitxml=junit/test-results.xml --cov=. --cov-report=xml --cov-report=html
            displayName: 'Test with pytest'
            workingDirectory: $(Pipeline.Workspace)/drop/blog-adfv2unittest-cicd
          - task: PublishTestResults@2
            condition: succeededOrFailed()
            inputs:
              testResultsFiles: '$(Pipeline.Workspace)/drop/blog-adfv2unittest-cicd/**/test-*.xml'
              testRunTitle: 'Publish test results for Python $(python.version)'